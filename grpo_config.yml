model:
  name: "sft-cot-model/best_model"

training:
  output_dir: "./grpo-cot-model"
  learning_rate: 2e-5
  min_lr_rate: 0.1
  batch_size: 4
  epochs: 2
  weight_decay: 0.01
  gradient_accumulation_steps: 8
  logging_steps: 30
  eval_steps: 150
  save_steps: 150
  save_total_limit: 2
  warmup_ratio: 0.05

grpo:
  num_generations: 4
  max_completion_length: 3096
  max_backtracking_word: 20
  temperature: 0.7
  top_p: 0.9

  reward_funcs:
    # "accuracy": 2.0
    format: 0.5
    # "reasoning_steps": 0.5
    # length: 0.3
    cosine: 2.0
    cosine_word: 0.5
    repetition_penalty: 0.1

  # Tham số reward nâng cao
  cosine_min_value_wrong: 0.0
  cosine_max_value_wrong: -0.5
  cosine_min_value_correct: 0.5
  cosine_max_value_correct: 1.0
  cosine_max_len: 12000 
  cosine_max_word: 20

  repetition_n_grams: 3
  repetition_max_penalty: -0.5

lora:
  using_lora: False
  r: 32
  lora_alpha: 64
  target_modules:
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "o_proj"
  lora_dropout: 0.05
  bias: "none"

dataset:
  train_path: "./data/val.json"
  val_ratio: 0.05
